{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align = 'center'>Text Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Avinash Pasupulate</h3>\n",
    "<br>\n",
    "<a href='mailto:avinash.pasupulate@gmail.com'><i>avinash.pasupulate@gmail.com</i></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status\n",
    "* Improving accuracy from \n",
    "<br>\n",
    "43%  - initial accuracy,\n",
    "<br>\n",
    "55.3% - Optimized min_df & max_df in tfidf,\n",
    "<br>\n",
    "75.7% - Included more data, Optimizing hypparms in logreg\n",
    "<br>\n",
    "79.20%  - Optimizing hypparms in random forest\n",
    "<br>\n",
    "current score 79.20%\n",
    "* Optimizing hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import copy\n",
    "import string\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn import preprocessing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import WordNetLemmatizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "stopwrd = set(stopwords.words('english'))\n",
    "cwd = os.getcwd()\n",
    "random.seed(2889)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listing all files in directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir(cwd+r'/data/reuters21578')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cwd+r'/data/reuters21578'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a list of filenames to import\n",
    "\n",
    "l = list(range(0,22))\n",
    "m = []\n",
    "for i in l:\n",
    "    if len(str(i))==1:\n",
    "        filename = '/reut2-00'+str(i)+'.sgm'\n",
    "        m.append(filename)\n",
    "    else:\n",
    "        filename = '/reut2-0'+str(i)+'.sgm'\n",
    "        m.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe with extracted text\n",
    "\n",
    "doc = pd.DataFrame()\n",
    "for i in m:\n",
    "    with open(data+i, 'rb') as f:\n",
    "        text = BeautifulSoup(f.read(), 'html.parser')\n",
    "        documents = text.findAll('reuters')\n",
    "        l=[]\n",
    "        for a in documents:\n",
    "            try:\n",
    "                topic = a.topics.find_all('d')[0].contents[0]\n",
    "                place = a.places.find_all('d')[0].contents[0]\n",
    "                title = a.title.contents[0].lower()\n",
    "                body = re.sub('\\n', ' ', a.body.contents[0].lower())\n",
    "                l.append([topic, place, title, body, i])\n",
    "            except:\n",
    "                pass\n",
    "        doc = doc.append(l, ignore_index = True, sort = True)\n",
    "doc.columns = ['topic', 'place', 'title', 'body', 'filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique categories in text: 80 in 10327 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"unique categories in text: {:} in {:} rows\"\n",
    "      .format(len(doc['topic'].unique()),len(doc['topic'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "tfidf_vector = TfidfVectorizer(analyzer = 'word',\n",
    "                               token_pattern = r'\\w{1,}',\n",
    "                               max_features = 100,\n",
    "                               lowercase = True,\n",
    "                               stop_words = 'english',\n",
    "                               max_df = 0.5,\n",
    "                               min_df = 0.01\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc['label'] = encoder.fit_transform(doc['topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    doc['body'], doc['label'], test_size = 0.25,\n",
    "    random_state = 28)\n",
    "actual = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change variable type and pass\n",
    "#tfidf_vector = tfidf_vector.fit(doc['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vector.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Support Vector Machine Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7362509682416731"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svcmod = SVC(kernel = 'rbf',\n",
    "             C=1,\n",
    "             gamma = 'scale')\n",
    "svcfit = svcmod.fit(X_train_tfidf, y_train)\n",
    "svc_pred = svcfit.predict(X_test_tfidf)\n",
    "accuracy_score(actual, svc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Multinomial Naive Bayes Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7176607281177382"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_mod = MultinomialNB(alpha = 0.01)\n",
    "mnb_fit = mnb_mod.fit(X_train_tfidf, y_train)\n",
    "mnb_score = accuracy_score(actual, mnb_fit.predict(X_test_tfidf))\n",
    "mnb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Multiclass Regression Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7563903950426026"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logmod = LogisticRegression(multi_class='multinomial',\n",
    "                            solver='saga',\n",
    "                            C=1,\n",
    "                            penalty = 'l2',\n",
    "                            random_state = 28,\n",
    "                            max_iter = 150,\n",
    "                            n_jobs = -1)\n",
    "logfit = logmod.fit(X_train_tfidf, y_train)\n",
    "accuracy_score(actual, logfit.predict(X_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Random Forest Classifier</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7920216886134779"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfmod = RandomForestClassifier(n_estimators = 250,\n",
    "                               random_state = 28,\n",
    "                               criterion = 'gini',\n",
    "                               bootstrap = False,\n",
    "                               max_depth = 100,\n",
    "                               n_jobs = -1)\n",
    "rffit = rfmod.fit(X_train_tfidf, y_train)\n",
    "accuracy_score(actual, rffit.predict(X_test_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>K Nearest Neighbors Classifier</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
